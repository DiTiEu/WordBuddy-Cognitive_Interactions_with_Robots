{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6c079e",
   "metadata": {},
   "source": [
    "## Funzionamento pratico del programma\n",
    "\n",
    "### 1. Setup iniziale\n",
    "- Il programma parte dal file `main.py`, che rappresenta il punto di ingresso principale del sistema.\n",
    "- All'avvio, `main.py` carica:\n",
    "  - i **parametri generali** dal file `data/config.yaml` (es. indirizzo IP del robot, parametri di sicurezza, posizioni di default, soglie per la visione);\n",
    "  - la **lista delle parole disponibili** da `data/words.json`;\n",
    "  - eventuali **dati di calibrazione** (camera, marker ArUco, coordinate del tavolo) dalla cartella `data/calibration/`.\n",
    "  - fa scegliere comunicando anche a voce la **difficolt√†** (in questo caso solo quante lettere togliere ma si pu√≤ migliorare con sistemi pi√π complessi)\n",
    "\n",
    "\n",
    "### 2. Selezione e preparazione della parola\n",
    "\n",
    "Il modulo `game_logic.py` ha la funzione `select_word()` che sceglie una parola casuale dal dataset (o in base al livello impostato).\n",
    "\n",
    "La parola scelta viene comunicata al giocatore tramite TTS. A questo punto il robot posiziona sul tavolo alcune lettere iniziali, lasciando all‚Äôutente il compito di completarle.\n",
    "\n",
    "NB: All‚Äôinterno di una funzione:\n",
    "- Recupera le coordinate della griglia dal file di configurazione.\n",
    "- Fa muovere il robot in sequenza: sopra la cella ‚Üí scende ‚Üí apre o chiude il gripper ‚Üí torna in posizione di sicurezza.\n",
    "\n",
    "### 3. Interazione con l‚Äôutente\n",
    "\n",
    "Dopo che il robot ha posato i blocchi, il sistema invita l‚Äôutente a completare la parola.\n",
    "\n",
    "Il programma aspetta poi un input manuale o vocale\n",
    "\n",
    "### 4. Riconoscimento visivo\n",
    "\n",
    "Quando l‚Äôutente segnala di aver finito, `main.py` richiama `detect_letters()` di `vision.py`.\n",
    "\n",
    "Questa funzione:\n",
    "- Cattura un frame dalla camera\n",
    "- Corregge la prospettiva in base ai marker ArUco\n",
    "- Segmenta i blocchi\n",
    "- Riconosce le lettere tramite OCR (pytesseract) o classificatore\n",
    "- Restituisce una lista strutturata, ad esempio: [{'char': 'G', 'x': 120, 'y': 340}, {'char': 'A', 'x': 200, 'y': 340}, ...]\n",
    "\n",
    "### 5. Verifica della parola e logica del gioco\n",
    "\n",
    "Il risultato del riconoscimento viene passato a `game_logic.py`, che confronta la sequenza delle lettere con la parola target. Se la parola corrisponde, `check_word()` restituisce True, altrimenti False.\n",
    "\n",
    "### 6. Feedback e movimenti del robot\n",
    "\n",
    "Se `success == True`:\n",
    "say(\"Perfetto! Hai completato la parola!\")\n",
    "robot.celebrate()\n",
    "La funzione `celebrate()` magari esegue una piccola coreografia col braccio robotico (es. movimento su-gi√π o oscillazione rapida).\n",
    "\n",
    "Se `success == False`:\n",
    "say(\"Ops! Alcune lettere non sono corrette, prova di nuovo!\")\n",
    "robot.encourage()\n",
    "`encourage()` pu√≤ essere, ad esempio, una piccola rotazione del polso o accenno laterale.\n",
    "\n",
    "### 7. Log dei risultati e salvataggio\n",
    "\n",
    "A ogni sessione √® associato un salvataggio tramite funzione `log_result()` in `utils.py`:\n",
    "from utils import log_result\n",
    "log_result(target_word, detected_letters, success)\n",
    "\n",
    "text\n",
    "Genera un file CSV o JSON in `data/test_logs/` con, per ogni sessione:\n",
    "timestamp, parola, lettere_rilevate, esito, tempo_totale\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b4dfa",
   "metadata": {},
   "source": [
    "## Note Personali\n",
    "\n",
    "- Fissare con scotch/qualcosa di rigido le postazioni dei blocchi fissi per semplificare movimenti robot e visione artificiale (cos√¨ devo solo capire che lettera √® e non sov'√® il blocco anche)\n",
    "\n",
    "- fissare delle portazioni del robot muovendolo a mano e cos√¨ tenere conto delle posizioni dell parole\n",
    "\n",
    "- separiamo vocali e consonanti (di vocali 2 copie mentre di consonanti magari giusto un paio di doppie)\n",
    "\n",
    "- le parole pi√π lunghe di 6 lettere non ci sono, dovremo dire che lo faranno nelle ricerche future volendo insieme anche a tipo frasi o altri tipi di interazioni/feedback\n",
    "\n",
    "- se facciamo i log possiamo proporre una possibile continuazione del progetto come una profilazione degli studenti che tipo monitora il loro miglioramente in cui √® anche ointegrata un AI/ un sistema che √® in grado di analizzare gli errori e capire le carenze della gente per consigliare le parole pi√π adatte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390817fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f8322",
   "metadata": {},
   "source": [
    "# Struttura della Presentazione ‚Äì WordBuddy (Progress Update)\n",
    "\n",
    "---\n",
    "\n",
    "## 1 Titolo e Introduzione\n",
    "\n",
    "**Titolo progetto:** WordBuddy ‚Äì Interactive Robot for Learning Words  \n",
    "**Corso:** Cognitive Interaction with Robots  \n",
    "**Team:** [Nome 1], [Nome 2], [Nome 3]  \n",
    "\n",
    "**Obiettivo generale:** creare un sistema interattivo dove un robot UR3 aiuta a comporre parole con blocchi lettera, usando visione artificiale e voce.\n",
    "\n",
    "**Stato attuale:** struttura completata, codice organizzato, robot funzionante con movimenti base.\n",
    "\n",
    "\n",
    "## 2Ô∏è Contesto e Obiettivi\n",
    "\n",
    "**Motivazione:** rendere l‚Äôapprendimento pi√π interattivo e ‚Äúfisico‚Äù per bambini e studenti.\n",
    "\n",
    "**Obiettivi principali:**\n",
    "- Insegnamento ludico di parole tramite robotica.\n",
    "- Interazione multimodale: voce, movimento, visione.\n",
    "- Esperienza user-centered, con feedback positivi e incoraggianti.\n",
    "- **Futuro:** estendere il sistema a frasi, livelli di difficolt√† e analisi automatica dei progressi.\n",
    "\n",
    "\n",
    "## 3Ô∏è Architettura generale del sistema\n",
    "\n",
    "**Componenti principali:**\n",
    "- `main.py` ‚Üí gestisce il flusso del gioco\n",
    "- `robot_control.py` ‚Üí controlla i movimenti del robot\n",
    "- `vision.py` ‚Üí riconosce le lettere con la camera\n",
    "- `game_logic.py` ‚Üí gestisce la parola target e controlla la correttezza\n",
    "- `tts_module.py` ‚Üí voce e comunicazione\n",
    "- `utils.py` ‚Üí logging e configurazioni\n",
    "\n",
    "üß≠ Abbiamo definito chiaramente come ogni modulo interagir√† con gli altri.\n",
    "\n",
    "*(Qui mostra uno schema logico a blocchi o con frecce tra i moduli)*\n",
    "\n",
    "\n",
    "## 4Ô∏è Flusso operativo del programma\n",
    "\n",
    "**Sequenza operativa:**\n",
    "1. Setup ‚Üí caricamento configurazioni, connessione robot e camera.\n",
    "2. Selezione parola ‚Üí `game_logic` sceglie la parola target.\n",
    "3. Il robot posiziona le prime lettere ‚Üí `robot_control` muove il braccio.\n",
    "4. L‚Äôutente completa la parola con i blocchi mancanti.\n",
    "5. La camera cattura l‚Äôimmagine ‚Üí `vision` riconosce le lettere.\n",
    "6. `game_logic` confronta risultato e genera feedback.\n",
    "7. `tts_module` comunica il messaggio vocale.\n",
    "8. `utils` salva log (successo/errore, tempi, ecc.).\n",
    "\n",
    "üí° Il codice √® gi√† strutturato per supportare tutto questo flusso, anche se non ancora completo.\n",
    "\n",
    "\n",
    "## 6Ô∏è Progresso tecnico\n",
    "\n",
    "**‚úÖ Controllo robot:**\n",
    "- Siamo riusciti a muovere il robot UR3 manualmente e via Python.\n",
    "- Abbiamo capito come definire posizioni fisse e come salvare i punti di pick & place.\n",
    "- Il passo successivo sar√† automatizzare questi movimenti con le lettere.\n",
    "\n",
    "**‚úÖ Visione artificiale:**\n",
    "- Camera fissata in posizione overhead.\n",
    "- Stampa dei marker ArUco per calibrazione.\n",
    "- Studio iniziale dell‚ÄôOCR (pytesseract) per il riconoscimento delle lettere.\n",
    "\n",
    "**‚úÖ Struttura del codice:**\n",
    "- Tutti i moduli principali sono gi√† creati.\n",
    "- Chiamate tra file e flusso di esecuzione definiti.\n",
    "\n",
    "\n",
    "## 7Ô∏è Note pratiche e design fisico\n",
    "\n",
    "**Decisioni e accorgimenti tecnici presi finora:**\n",
    "- Blocchi fissati con scotch o supporto rigido per semplificare movimenti e visione.\n",
    "- Posizioni del robot salvate manualmente per ogni cella di parola.\n",
    "- Separazione lettere:\n",
    "  - Vocali ‚Üí 2 copie.\n",
    "  - Consonanti ‚Üí 1 copia (alcune doppie).\n",
    "- Parole massimo 6 lettere (per semplicit√† e tempo di interazione).\n",
    "- Tutte le posizioni del tavolo gi√† pianificate per ridurre errori di visione.\n",
    "\n",
    "\n",
    "## 8Ô∏è Piano di sviluppo\n",
    "\n",
    "| Settimana | Attivit√†                                  | Obiettivo                                    |\n",
    "|:---------:|:------------------------------------------|:----------------------------------------------|\n",
    "| 1         | Rifinitura movimenti base UR3             | Movimenti precisi su griglia                  |\n",
    "| 2         | Integrazione visione ‚Üí OCR su blocchi     | Riconoscimento lettere base                   |\n",
    "| 3         | Unione visione + logica + voce            | Gioco end-to-end semplice                     |\n",
    "| 4         | Test e raccolta log                       | Analisi errori e tempi                        |\n",
    "| 5         | Preparazione demo finale                  | Fluida e con feedback vocali                  |\n",
    "\n",
    "\n",
    "## 9Ô∏è Visione futura e possibili estensioni\n",
    "\n",
    "üöÄ **Estensioni future:**\n",
    "- Parole pi√π lunghe ‚Üí fino a frasi complete.\n",
    "- Analisi automatica dei log per profilare i progressi degli studenti.\n",
    "- Integrazione di un sistema AI adattivo che consiglia parole in base agli errori (personalizzazione del percorso di apprendimento).\n",
    "- Introduzione di gesture e movimenti pi√π naturali per rendere il robot ‚Äúpi√π sociale‚Äù.\n",
    "- Supporto a interazioni vocali (es. ‚ÄúRipeti la parola‚Äù, ‚ÄúProva di nuovo‚Äù).\n",
    "\n",
    "\n",
    "## 10 Conclusione\n",
    "\n",
    "Abbiamo:\n",
    "- Definito la struttura del progetto e il flusso logico completo.\n",
    "- Capito come le varie componenti interagiranno.\n",
    "- Eseguito movimenti base del robot e setup hardware (camera, blocchi, marker).\n",
    "- Steso un piano di sviluppo realistico fino alla demo finale.\n",
    "\n",
    "**Prossimo passo:** unire tutto in un ciclo interattivo completo e iniziare i test.  \n",
    "üß© Siamo ancora all‚Äôinizio, ma con una struttura chiara e un piano concreto: la base √® solida e pronta per crescere.\n",
    "\n",
    "\n",
    "## üí¨ (Facoltativo) Slide finale con immagine o video\n",
    "\n",
    "Se avete foto:\n",
    "- del tavolo con i blocchi,\n",
    "- dei marker ArUco stampati,\n",
    "- della camera montata,\n",
    "- o del robot in movimento,\n",
    "\n",
    "inserite una slide finale visiva (aiuta molto nella presentazione).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
